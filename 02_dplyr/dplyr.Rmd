---
title: "Data Manipulation: Intro to `dplyr`"
author: "Emorie D Beck"
output:
  html_document:
    theme: united
    highlight: tango
    code_folding: show
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, cache = F)
```

```{r}
library(psych)
library(dplyr)
```

# `dplyr`  
The `dplyr` package is a powerful set of tools from within the larger `tidyverse` suite of functions. `dplyr` functions are useful for a variety of functions, perhaps particularly data manipulation.  

Although there are a large number of functions within the `dplyr` package, today I'm going to introduce a subset of them along with a small number of use cases. But don't worry, these functions will be the key underpinning of code I use in all tutorials going forward, so there will be lots more examples and use cases.  

For now, here's a quick list of the functions we'll cover today:  

1. `%>%`: The pipe. Read as "and then."  
2. `filter()`: Pick observations (rows) by their values.  
3. `select()`: Pick variables (columns) by their names.  
4. `arrange()`: Reorder the rows.  
5. `group_by()`: Implicitly split the data set by grouping by names (columns).  
6. `mutate()`: Create new variables with functions of existing variables.  
7. `summarize()` / `summarise()`: Collapse many values down to a single summary.  

Although each of these functions are powerful alone, they are incredibly powerful in conjunction with one another. So below, I'll briefly introduce each function, then link them all together using an example of basic data cleaning and summary.  


# Key `dplyr` Functions  

## 1. `%>%`  
The pipe `%>%` is wonderful. It makes coding intuitive. Often in coding, you need to use so-called nested functions. For example, you might want to round a number after taking the square of 43.  

```{r}
sqrt(43)

round(sqrt(43), 2)
```

The issue with this comes whenever we need to do a series of operations on a data set or other type of object. In such cases, if we run it in a single call, then we have to start in the middle and read our way out.  

The pipe solves this by allowing you to read from left to right (or top to bottom). The easiest way to think of it is that each call of `%>%` reads and operates as "and then." So with the rounded square root of 43, for example: 

```{r}
sqrt(43) %>%
  round(2)
```

As you can see, the two results are the same but the second is slightly easier to follow. And, as you'll see below, this becomes even more intuitive when you start using it in conjunction with `dplyr` functions.  

## 2. `filter()`  
Often times, when conducting research (experiments or otherwise), there are observations (people, specific trials, etc.) that you don't want to include. 

Say for example, that you're interested personality change in adolescence, but you just opened a survey up online. So when you actually download and examine your data, you realize that you have an age range of something like 3-86, not 12-18. In this case, you want to get rid of the people over 18 -- that is, `filter()` them out.  

```{r}
data(bfi) # grab the bfi data from the psych package
bfi <- bfi %>% as_tibble()

summary(bfi$age) # get age descriptives

bfi2 <- bfi %>% # see a pipe!
  filter(age <= 18) # filter to age up to 18

summary(bfi2$age) # summary of the new data 
```

But this isn't quite right. We still have folks below 12. But, the beauty of `filter()` is that you can do sequence of `OR` and `AND` statements when there is more than one condition, such as up to 18 `AND` at least 12.  

```{r}
bfi2 <- bfi %>%
  filter(age <= 18 & age >= 12) # filter to age up to 18 and at least 12

summary(bfi2$age) # summary of the new data 
```

Got it!  

But filter works for more use cases than just conditional `<`, `>`, `<=`, and `>=`. It can also be used for cases where we want a single values to match cases with text. Before I demonstrate that, though, I need to convert one of the variables in the `bfi` data frame to a string. So let's change gender (1 = male, 2 = female) to text (we'll get into factors later).  

```{r}
bfi$education <- plyr::mapvalues(bfi$education, 1:5, c("Below HS", "HS", "Some College", "College", "Higher Degree"))
```

Now let's try a few things: 

**1. Create a data set with only individuals with some college (`==`).**  

```{r}
bfi2 <- bfi %>% 
  filter(education == "Some College")
unique(bfi2$education)
```

**2. Create a data set with only people age 18 (`==`).**  

```{r}
bfi2 <- bfi %>%
  filter(age == 18)
summary(bfi2$age)
```

**3. Create a data set with individuals with some college or above (`%in%`).**  

```{r}
bfi2 <- bfi %>%
  filter(education %in% c("Some College", "College", "Higher Degree"))
unique(bfi2$education)
```

The `%in%` operator is wonderful. Instead of comparing a column to a single value, you can compare it to several. So above, when we wanted ages between 12 and 18, we could have done:  

```{r}
bfi2 <- bfi %>%
  filter(age %in% 12:18)
summary(bfi2$age)
```

I've been using `dplyr` for nearly five years, and I still have to remind myself that when you want to remove rows, you use `filter()`.  

## 3. `select()`  
If `filter()` is for pulling certain observations (rows), then `select()` is for pulling certain variables (columns). Almost without fail, any data that are received for collected are going to have some variables that are not used, not useful, extraneous, etc. In such cases, it's good practice to remove these columns to stop your environment from becoming cluttered and eating up your RAM. 

In our `bfi` data, most of these have been pre-removed, so instead, we'll imagine we don't want to use any indicators of Agreeableness (A1-A5) and that we aren't interested in gender.  

With `select()`, there are few ways choose variables. We can bare quote name the ones we want to keep, bare quote names we want to remove, or use any of a number of `select()` helper functions.  

**1. Bare quote columns we want to keep:**  
```{r}
bfi %>%
  select(C1, C2, C3, C4, C5)
```

I'm going to stop there because I don't want to name the additional 17 columns we want to keep. Instead we'll use `:` to grab a *range* of columns.  

```{r}
bfi %>%
  select(C1:O5, education, age)
```

**2. Bare quote columns we don't want to keep:**  

```{r}
bfi %>% 
  select(-(A1:A5), -gender)
```

Note the `()` around the columns. That is necessary when you want to remove a range of columns. 

**3. Add or remove using `select()` helper functions.**  

* `starts_with()`: matches names that begin with quoted argument. For example, if we wanted all the Conscientiousness items, we could call the following:  

```{r}
bfi %>%
  select(starts_with("C"))
```

* `ends_with()`: matches names that end with quoted argument. For example, if we wanted the first item in each Big Five scale, we could call:  

```{r}
bfi %>% 
  select(ends_with("1"))
```

* `contains()`: matches names that contain quote material. This can be any subset of a string, which makes it very useful for a number of contexts we'll see later. But for now, if I wanted to be lazy or couldn't remember the name of th education variable, I could call:  

```{r}
bfi %>% 
  select(contains("edu"))
```

* `matches()`: selects variables that match a regular expression (regex). Regex is tricky. I tend to end up referencing online documentation when I need to use this beyond a few basic expressions that I use very regularly. We'll start with a simple one, keeping only those variables that either have or do not have numbers:   

```{r}
# contains numbers
bfi %>%
  select(matches("[0-9]")) 

# does not contain numbers
bfi %>%
  select(!matches("[0-9]")) 
```

* `num_range()`: Given a stem and a range of numbers, this selects items in a sequence. This is especially useful when variables of your data set may not be in order.  

```{r}
# select first 2 Extraversion items
bfi %>%
  select(num_range("E", 1:2))
```

* `one_of()`: select any of a subset of items from a vector. This is one of my favorites, for reasons we'll see in my tutorial on workflow and data documentation. But for now, let's say I thought there were six items in each personality when there are actually five. So when I call the following, `one_of()` will be forgiving and ignore the fact that I messed up.  

```{r}
bfi %>% 
  select(one_of(paste0("E", 1:6)))
```

* `all_of()`: select all of a subset of items from a vector. Unlike `one_of()`, `all_of()` is less forgiving and will throw an error if we try to call for 6 Extraversion items.  

```{r, error=TRUE}
bfi %>%
  select(all_of(paste0("E", 1:6)))
```

Oops. In this case, we'd then need to modify the code to reflect the correct number of items.  

```{r}
bfi %>%
  select(all_of(paste0("E", 1:5)))
```

## 4. `arrange()` 
Sometimes, either in order to get a better sense of our data or in order to well, order our data, we want to sort it. Although there is a base `R` `sort()` function, the `arrange()` function is `tidyverse` version that plays nicely with other `tidyverse functions`. 

So in our previous examples, we could also `arrange()` our data by age or education, rather than simply filtering. (Or as we'll see later, we can do both!)  

```{r}
# sort by age
bfi %>% 
  select(gender:age) %>%
  arrange(age)

# sort by education
bfi %>%
  select(gender:age) %>%
  arrange(education)
```

We can also arrange by multiple columns, like if we wanted to sort by gender then education:  

```{r}
bfi %>%
  select(gender:age) %>%
  arrange(gender, education)
```


# Bringing it all together: Split-Apply-Combine  
Much of the power of `dplyr` functions lay in the split-apply-combine method. The method is kind of what it sounds like. A given set of of data are *split* into smaller chunks, then a function or series of functions are *applied* to each chunk, and then the chunks are *combined* back together. 

Although all of the `dplyr` functions can be used in conjunction with one another, I'm going to highlight the `group_by()`, `mutate()`, and `summarize()` / `summarise()` functions to highlight the core of the split-apply-combine method.  

## 5. `group_by()`  

The `group_by()` function is the "split" of the method. It basically implicitly breaks the data set into chunks by whatever bare quoted column(s)/variable(s) are supplied as arguments.  

So imagine that we wanted to `group_by()` education levels to get average ages at each level. We would simply call: 

```{r}
bfi %>%
  select(starts_with("C"), age, gender, education) %>%
  group_by(education)
```

We can now see that it tells us that we have a tibble with 2,800 rows and 8 columns as well as `Groups:   education [6]`  

Importantly, once you group, you must `ungroup()` or your data frame will remain "split" and cause you problems. In other words, you must "combine" your data frame back together. This is super easy with the `ungroup()` function:  

```{r}
bfi %>%
  select(starts_with("C"), age, gender, education) %>%
  group_by(education) %>%
  ungroup()
```

You can also overwrite groups by calling `group_by()` more than once. We'll touch more on that in future tutorials, but for now, notice what happens when I call `group_by()` twice sequentially:  

```{r}
bfi %>%
  select(starts_with("C"), age, gender, education) %>%
  group_by(education) %>%
  group_by(gender, age)
```

Note that the resulting data frame is not grouped by education at all, but by gender and age (i.e. it is not cumulative).  

## 6. `mutate()`  

The `mutate()` function is one of a few options for how to "apply" (a) function(s) to your split (i.e. `group_by()`) data frame. When you use `mutate()`, the resulting data frame will have the same number of rows you started with (which will not be true with `summarize()` / `summarise()`). One way to remember is this is that you are directly mutating the existing data frame, either modifying existing columns or creating new ones. 

So to continue with the example above, if we were to add a column that indicated average age levels within each age group, we would call:  

```{r}
bfi %>%
  select(starts_with("C"), age, gender, education) %>%
  arrange(education) %>%
  group_by(education) %>% 
  mutate(age_by_edu = mean(age, na.rm = T))
```

As you can see in the resulting data frame, each person (row) with the same education level has the same value in the new `age_by_edu` column I just added.  

`mutate()` is also super useful even when you aren't grouping. For example, if I wanted to recode gender so that 1 = "male" and 2 = "female," we could do that like: 

```{r}
bfi %>%
  select(starts_with("C"), age, gender, education) %>%
  mutate(gender_cat = plyr::mapvalues(gender, c(1,2), c("Male", "Female")))
```

We could also just write over the original gender category like:  

```{r}
bfi %>%
  select(starts_with("C"), age, gender, education) %>%
  mutate(gender = plyr::mapvalues(gender, c(1,2), c("Male", "Female")))
```


## 7. `summarize()` / `summarise()`  

The `summarize()` / `summarise()` functions (choose your spelling as you will) is another of the options for how to "apply" (a) function(s) to your split (i.e. `group_by()`) data frame. When you use `summarize()` (I made by choice), the resulting data frame will have the number of rows equal to the number of `group_by()` categories you provide. So if you provided `education`, that will be 6, and if you provided none, it would be one.  

```{r}
# group_by() education
bfi %>%
  select(starts_with("C"), age, gender, education) %>%
  arrange(education) %>%
  group_by(education) %>% 
  summarize(age_by_edu = mean(age, na.rm = T))  

# no groups  
bfi %>% 
  select(starts_with("C"), age, gender, education) %>%
  arrange(education) %>%
  summarize(age_by_edu = mean(age, na.rm = T))  
```

From this, for example, it becomes clear that all the `NA`s in the `education` variable were because they reflected 18 year olds who had not yet completed high school as well as that the sample is pretty young overall.  

# Conclusion  

This has been a quick and relatively low level introduction into some of the core functions in the `dplyr` package. I challenge you to try to take what you learned and apply it to some of your own data.  

In the next tutorial, we will touch on data wrangling, introducing the `tidyr` packages. This will provide methods for changing the shape for your data, which, in turn, will open up new opportunities to use `dplyr` functions in useful ways. We will then take all of that and roll it into additional packages and tools.  
